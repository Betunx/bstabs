# üé∏ Gu√≠a Completa de Scraping - Black Sheep Tabs

## üÜï NUEVO: Soporte para PDFs

El scraper ahora puede extraer tablaturas desde:
- ‚úÖ **HTML** (CifraClub, AcordesWeb, Ultimate Guitar, etc.)
- ‚úÖ **PDF** (URLs de PDFs o archivos locales)
- ‚úÖ **Batch** (procesar m√∫ltiples URLs de una vez)

---

## üöÄ Inicio R√°pido

### Instalaci√≥n

```bash
cd scripts/scraper
npm install
```

Dependencias instaladas:
- `pdf-parse`: Para extraer texto de PDFs

### Uso B√°sico

```bash
# Una URL de PDF
node tab-scraper-v2.js "https://acordesweb.com/descarga-pdf/artista/cancion/0/0/0.pdf"

# Una URL de HTML
node tab-scraper-v2.js "https://cifraclub.com.br/artista/cancion/"

# Un archivo PDF local
node tab-scraper-v2.js "./mi-tablatura.pdf"

# Batch (m√∫ltiples URLs)
node tab-scraper-v2.js --batch urls-ejemplo.txt
```

---

## üìã Preparar URLs para Scraping

### 1. Crear archivo de URLs

Crea un archivo de texto (ej: `mis-canciones.txt`):

```txt
# Canciones de Natanael Cano
https://acordesweb.com/descarga-pdf/natanael-cano/viejo-lobo-ft-luis-r-conriquez/0/0/0.pdf
https://acordesweb.com/descarga-pdf/natanael-cano/amor-tumbado/0/0/0.pdf

# Canciones de Peso Pluma
https://acordesweb.com/descarga-pdf/peso-pluma/ella-baila-sola/0/0/0.pdf

# Archivos locales
./descargas/mi-cancion.pdf
```

**Notas importantes**:
- L√≠neas con `#` son comentarios (ignoradas)
- Soporta URLs HTTP/HTTPS y rutas de archivos locales
- Una URL o archivo por l√≠nea

### 2. Ejecutar batch

```bash
node tab-scraper-v2.js --batch mis-canciones.txt
```

### 3. Resultados

Los archivos extra√≠dos se guardan en:
```
scripts/scraper/extracted-tabs/
‚îú‚îÄ‚îÄ viejo-lobo-ft-luis-r-conriquez-1234567890.json
‚îú‚îÄ‚îÄ amor-tumbado-1234567891.json
‚îú‚îÄ‚îÄ ella-baila-sola-1234567892.json
‚îî‚îÄ‚îÄ batch-summary.json
```

---

## üìÑ Formato de Salida (JSON)

### Ejemplo extra√≠do de PDF:

```json
{
  "title": "Viejo Lobo",
  "artist": "Natanael Cano ft Luis R Conriquez",
  "sourceUrl": "https://acordesweb.com/descarga-pdf/...",
  "sourceType": "pdf",
  "extractedAt": "2025-12-22T...",
  "status": "pending",
  "chords": ["Am", "G", "F", "C", "Dm", "E7"],
  "sections": [
    {
      "name": "Intro",
      "lines": [
        "Am        G",
        "En la sierra nac√≠..."
      ]
    },
    {
      "name": "Verso 1",
      "lines": [
        "Am             G",
        "Viejo lobo me dicen por ah√≠",
        "        F              C",
        "Porque nunca me dejo agarrar"
      ]
    }
  ],
  "rawText": "Intro\nAm G\nEn la sierra nac√≠..."
}
```

### Campos explicados:

- **title**: T√≠tulo de la canci√≥n (extra√≠do de URL o contenido)
- **artist**: Artista (extra√≠do de URL o metadata)
- **sourceUrl**: URL de donde se extrajo
- **sourceType**: `"pdf"` o `"html"`
- **extractedAt**: Timestamp de extracci√≥n
- **status**: Siempre `"pending"` (pendiente de revisi√≥n)
- **chords**: Array de acordes √∫nicos detectados
- **sections**: Secciones estructuradas (Intro, Verso, Coro, etc.)
- **rawText**: Texto completo sin procesar

---

## üîß C√≥mo Funciona

### Detecci√≥n Autom√°tica de Formato

El scraper detecta autom√°ticamente si la URL es:

1. **PDF**: Revisa los primeros 4 bytes (`%PDF`)
2. **HTML**: Todo lo dem√°s

### Extracci√≥n de PDFs

```
URL ‚Üí Descarga Buffer ‚Üí pdf-parse ‚Üí Texto plano ‚Üí
‚Üí Detecta acordes ‚Üí Organiza secciones ‚Üí JSON
```

**Ventajas**:
- Extrae TODO el texto del PDF
- No depende de HTML/CSS
- Funciona con PDFs escaneados (si tienen texto)

**Limitaciones**:
- PDFs solo con im√°genes NO funcionan (requiere OCR)
- La estructura puede variar seg√∫n el PDF

### Extracci√≥n de HTML

```
URL ‚Üí Descarga HTML ‚Üí Busca <pre> tags ‚Üí Limpia basura ‚Üí
‚Üí Detecta acordes ‚Üí JSON
```

**Sitios soportados**:
- AcordesWeb (HTML)
- CifraClub
- Ultimate Guitar
- Gen√©rico (cualquier sitio con `<pre>` tags)

---

## üìä Detecci√≥n de Secciones

El scraper identifica secciones autom√°ticamente buscando keywords:

| Keyword | Detecta como |
|---------|--------------|
| intro, introduction | Intro |
| verse, verso | Verso |
| chorus, coro, estribillo | Coro |
| bridge, puente | Puente |
| outro, final | Final |
| solo | Solo |
| pre-chorus, pre-coro | Pre-Coro |

**Ejemplo**:
```
Intro
Am G F C

Verso 1
Am              G
En la sierra nac√≠
```

Se convierte en:
```json
{
  "sections": [
    {
      "name": "Intro",
      "lines": ["Am G F C"]
    },
    {
      "name": "Verso 1",
      "lines": ["Am              G", "En la sierra nac√≠"]
    }
  ]
}
```

---

## üéØ Flujo Completo de Trabajo

### 1. Recolectar URLs

Busca canciones en AcordesWeb, CifraClub, etc. y copia las URLs:

**Para PDFs de AcordesWeb**:
- Ve a la canci√≥n
- Busca el bot√≥n "Descargar PDF"
- Copia el link del bot√≥n (clic derecho ‚Üí Copiar direcci√≥n del enlace)

**Para HTML**:
- Solo copia la URL de la p√°gina

### 2. Crear lista de URLs

```bash
cd scripts/scraper
nano mis-urls.txt
# Pega las URLs, una por l√≠nea
```

### 3. Ejecutar scraper

```bash
node tab-scraper-v2.js --batch mis-urls.txt
```

**Output esperado**:
```
üìã Procesando 10 URLs...

üéµ Procesando: https://acordesweb.com/.../viejo-lobo.pdf
   Tipo detectado: PDF
üìÑ PDF parseado correctamente
   P√°ginas: 2
   Caracteres: 1523
‚úÖ Guardado: extracted-tabs/viejo-lobo-1703234567.json
üìä Acordes: Am, G, F, C, Dm, E7, G7, Cmaj7...
üìë Secciones: Intro, Verso 1, Coro, Verso 2, Puente

... (contin√∫a con las dem√°s URLs)

üì¶ Resumen: extracted-tabs/batch-summary.json
‚úÖ √âxitosos: 9/10
```

### 4. Revisar resultados

```bash
cd extracted-tabs
ls -lh
cat viejo-lobo-*.json | head -50
```

### 5. Importar a la base de datos

```bash
# M√©todo 1: Import individual
node import-to-db.js http://localhost:3000

# M√©todo 2: Import batch (m√°s r√°pido)
node import-to-db.js http://localhost:3000 batch
```

**Nota**: Requiere que el backend est√© corriendo y configurado con API key.

### 6. Revisar en Admin Dashboard

1. Abre `http://localhost:4200/admin`
2. Ve a "Pending Tabs"
3. Revisa cada canci√≥n
4. Edita si es necesario
5. Publica cuando est√© lista

---

## üõ†Ô∏è Troubleshooting

### Error: "Cannot find module 'pdf-parse'"

```bash
cd scripts/scraper
npm install
```

### Error: "No se pudo extraer contenido"

**Posibles causas**:
1. PDF es solo imagen (requiere OCR, no soportado)
2. HTML usa estructura no est√°ndar
3. Sitio bloque√≥ el request (usar header User-Agent)

**Soluci√≥n temporal**:
- Descarga el PDF manualmente
- Ejecuta: `node tab-scraper-v2.js ./descargado.pdf`

### Acordes mal detectados

El regex de detecci√≥n es:
```regex
/\b([A-G][#b]?(?:m|maj|min|aug|dim|sus|add)?[0-9]?(?:\/[A-G][#b]?)?)\b/g
```

Detecta: `Am`, `G7`, `Cmaj7`, `F#m`, `D/F#`, etc.

Si falta alg√∫n formato, edita el JSON manualmente despu√©s.

### Secciones mal organizadas

Edita el JSON antes de importar:

```json
{
  "sections": [
    {
      "name": "Verso 1",  // ‚Üê Cambia esto
      "lines": [...]
    }
  ]
}
```

---

## üìù Tips y Mejores Pr√°cticas

### 1. Usa PDFs cuando sea posible
- M√°s limpio que HTML
- No tiene ads ni scripts
- Extracci√≥n m√°s consistente

### 2. Procesa en batches peque√±os
- 10-20 URLs a la vez
- Revisa los resultados antes de continuar
- Evita sobrecargar los servidores (delay de 3 segundos entre requests)

### 3. Respeta las fuentes
- Incluye siempre `sourceUrl` en el JSON
- Muestra cr√©ditos en tu app
- No republiques sin permiso

### 4. Revisa antes de publicar
- Los PDFs pueden tener errores de formato
- Verifica acordes y letra
- Corrige typos

### 5. Organiza tus URLs
- Agrupa por artista
- Usa comentarios en el archivo
- Mant√©n un log de lo ya scraped

---

## üîê Configuraci√≥n sin Login/Autenticaci√≥n

Como NO vas a usar login por ahora:

### Opci√≥n 1: API Key en `.env`

```env
# backend/.env
ADMIN_API_KEY=tu-clave-secreta-aqui-12345
```

Al importar, incluye el header:

```bash
# Modifica import-to-db.js para incluir:
headers: {
  'x-api-key': 'tu-clave-secreta-aqui-12345'
}
```

### Opci√≥n 2: Importaci√≥n directa a BD (sin API)

Crea un script que inserte directamente en PostgreSQL:

```javascript
// direct-import.js
const { Pool } = require('pg');
const fs = require('fs');

const pool = new Pool({
  host: 'localhost',
  database: 'blacksheep',
  user: 'postgres',
  password: 'tu-password'
});

const json = JSON.parse(fs.readFileSync('./extracted-tabs/tab.json'));

await pool.query(
  'INSERT INTO songs (title, artist, content, chords, status) VALUES ($1, $2, $3, $4, $5)',
  [json.title, json.artist, json.rawText, json.chords, 'pending']
);
```

---

## üéØ Siguiente Paso

Una vez que tengas tabs extra√≠dos:

1. **Revisi√≥n**: Abre el admin dashboard
2. **Edici√≥n**: Corrige errores si hay
3. **Publicaci√≥n**: Cambia status a `published`
4. **Verificaci√≥n**: Prueba en el front end

Ver [PLAN_ESTRATEGICO.md](../PLAN_ESTRATEGICO.md) para el flujo completo.

---

## üìö Recursos

- [AcordesWeb](https://acordesweb.com) - PDFs limpios
- [CifraClub](https://cifraclub.com.br) - HTML estructurado
- [Ultimate Guitar](https://tabs.ultimate-guitar.com) - Requiere login

---

**Happy Scraping! üé∏**
