# ðŸŽ¸ Black Sheep Scraper - GuÃ­a de Uso

## ðŸš€ Flujo Completo: Scraping â†’ Base de Datos

### Paso 1: Configurar PostgreSQL

#### Instalar PostgreSQL (Windows)

**OpciÃ³n A: Instalador Oficial**
1. Descarga: https://www.postgresql.org/download/windows/
2. Instala (usuario: `postgres`, password: elige una)
3. Instala pgAdmin (viene incluido)

**OpciÃ³n B: Docker**
```bash
docker run --name blacksheep-db \
  -e POSTGRES_PASSWORD=admin123 \
  -e POSTGRES_DB=blacksheep \
  -p 5432:5432 \
  -d postgres:15
```

#### Crear Base de Datos

OpciÃ³n 1 - pgAdmin:
1. Abre pgAdmin
2. Right click "Databases" â†’ Create â†’ Database
3. Nombre: `blacksheep`

OpciÃ³n 2 - LÃ­nea de comandos:
```bash
psql -U postgres
CREATE DATABASE blacksheep;
\q
```

---

### Paso 2: Inicializar Esquema

Ejecuta el backend una vez para crear las tablas:

```bash
cd ../../backend/black-sheep-api

# Configura .env
echo "DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_USER=postgres
DATABASE_PASSWORD=admin123
DATABASE_NAME=blacksheep
ADMIN_API_KEY=mi-clave-secreta-123" > .env

# Ejecuta (crearÃ¡ las tablas automÃ¡ticamente)
npm run start:dev
```

VerÃ¡s en la consola:
```
[TypeORM] Query: CREATE TABLE "songs" (...)
[Nest] Application successfully started
```

**Â¡DetÃ©n el backend (Ctrl+C) despuÃ©s de ver esto!**

---

### Paso 3: Scraping de Canciones

#### Preparar URLs

Crea un archivo con las URLs:

```bash
# En scripts/scraper/
nano mis-urls.txt
```

Contenido de ejemplo:
```txt
# Corridos tumbados
https://acordesweb.com/descarga-pdf/natanael-cano/viejo-lobo-ft-luis-r-conriquez/0/0/0.pdf
https://acordesweb.com/descarga-pdf/natanael-cano/amor-tumbado/0/0/0.pdf
https://acordesweb.com/descarga-pdf/peso-pluma/ella-baila-sola/0/0/0.pdf

# ClÃ¡sicos
https://acordesweb.com/descarga-pdf/los-bunkers/llueve-sobre-la-ciudad/0/0/0.pdf
```

#### Ejecutar Scraper

```bash
cd scripts/scraper
node tab-scraper-v2.js --batch mis-urls.txt
```

Output:
```
ðŸ“‹ Procesando 4 URLs...

ðŸŽµ Procesando: https://acordesweb.com/.../viejo-lobo.pdf
   Tipo detectado: PDF
ðŸ“„ PDF parseado correctamente
âœ… Guardado: extracted-tabs/viejo-lobo-1234567.json
ðŸ“Š Acordes: Am, G, F, C, Dm, E7...

...

âœ… Ã‰xitosos: 4/4
```

Ahora tienes JSONs en `extracted-tabs/`

---

### Paso 4: Importar a Base de Datos

#### Configurar credenciales

OpciÃ³n 1 - Variables de entorno:
```bash
export DB_HOST=localhost
export DB_PORT=5432
export DB_USER=postgres
export DB_PASSWORD=admin123
export DB_NAME=blacksheep
```

OpciÃ³n 2 - Editar el script (lÃ­nea 296):
```javascript
const config = {
  host: 'localhost',
  port: 5432,
  database: 'blacksheep',
  user: 'postgres',
  password: 'TU_PASSWORD_AQUI',
};
```

#### Ejecutar importaciÃ³n

```bash
node import-direct-db.js
```

Output esperado:
```
âœ… Conectado a PostgreSQL

ðŸ“¦ Importando 4 canciones...

ðŸ“¤ Importando: Viejo Lobo
âœ… Importado: Viejo Lobo (ID: a3f2...)

ðŸ“¤ Importando: Amor Tumbado
âœ… Importado: Amor Tumbado (ID: b7d1...)

...

ðŸ“Š Resumen:
   Total archivos: 4
   Importados: 4
   Fallidos: 0

ðŸ“Š Estado de la base de datos:
   Total canciones: 4
   Pending: 4
   Published: 0
   Draft: 0

âœ… Desconectado de PostgreSQL
```

---

### Paso 5: Revisar en Admin Dashboard

1. Inicia el backend:
   ```bash
   cd ../../backend/black-sheep-api
   npm run start:dev
   ```

2. Inicia el frontend:
   ```bash
   cd ../../frontend/black-sheep-app
   npm start
   ```

3. Abre el navegador:
   ```
   http://localhost:4200/admin
   ```

4. VerÃ¡s las 4 canciones en estado "Pending"

5. Haz clic en una para editarla:
   - Corrige errores si hay
   - Verifica acordes y letra
   - Cambia status a "Published"

---

## ðŸ”„ Flujo Completo Resumido

```
1. Recolectar URLs â†’ mis-urls.txt

2. Scrapear:
   node tab-scraper-v2.js --batch mis-urls.txt

3. Importar a BD:
   node import-direct-db.js

4. Revisar en admin:
   http://localhost:4200/admin

5. Publicar cuando estÃ©n listas
```

---

## ðŸ“Š Comandos Ãštiles

### Ver canciones en PostgreSQL

```bash
# Conectar
psql -U postgres -d blacksheep

# Ver todas las canciones
SELECT id, title, artist, status FROM songs;

# Ver solo pendientes
SELECT title, artist FROM songs WHERE status = 'pending';

# Contar por estado
SELECT status, COUNT(*) FROM songs GROUP BY status;

# Salir
\q
```

### Ver contenido completo de una canciÃ³n

```sql
SELECT * FROM songs WHERE title LIKE '%Viejo Lobo%';
```

### Cambiar status manualmente

```sql
UPDATE songs SET status = 'published' WHERE title = 'Viejo Lobo';
```

### Eliminar una canciÃ³n

```sql
DELETE FROM songs WHERE title = 'Nombre de la canciÃ³n';
```

### Eliminar TODAS las canciones (Â¡cuidado!)

```sql
TRUNCATE TABLE songs;
```

---

## ðŸ› Troubleshooting

### Error: "Cannot connect to PostgreSQL"

**SoluciÃ³n**:
1. Verifica que PostgreSQL estÃ¡ corriendo:
   ```bash
   # Windows
   services.msc
   # Busca "postgresql" y verifica que estÃ¡ "Running"
   ```

2. Verifica credenciales en `import-direct-db.js`

3. Intenta conectar manualmente:
   ```bash
   psql -U postgres
   ```

### Error: "Table 'songs' does not exist"

**SoluciÃ³n**:
Ejecuta el backend primero para crear las tablas:
```bash
cd ../../backend/black-sheep-api
npm run start:dev
# Espera a que arranque
# Ctrl+C para detener
```

### Error: "No hay archivos JSON para importar"

**SoluciÃ³n**:
Primero ejecuta el scraper:
```bash
node tab-scraper-v2.js --batch mis-urls.txt
```

### Las canciones se importan pero no se ven en el admin

**SoluciÃ³n**:
1. Verifica que el backend estÃ© corriendo
2. Verifica la conexiÃ³n a BD en el backend `.env`
3. Revisa la consola del backend por errores

---

## ðŸ’¡ Tips

### 1. Importa en batches pequeÃ±os
- 10-20 canciones a la vez
- Revisa los resultados
- Ajusta si es necesario

### 2. Backup antes de importar masivo
```bash
pg_dump -U postgres blacksheep > backup.sql
```

Restaurar:
```bash
psql -U postgres blacksheep < backup.sql
```

### 3. Limpia archivos procesados
```bash
# DespuÃ©s de importar exitosamente
rm extracted-tabs/*.json
```

### 4. MantÃ©n un log de URLs procesadas
```bash
# Crea un archivo de registro
echo "$(date): Procesadas 20 URLs" >> scraping-log.txt
```

---

## ðŸŽ¯ Siguientes Pasos

Una vez que tengas canciones en la BD:

1. **Revisar** desde admin dashboard
2. **Editar** detalles (tempo, dificultad, etc.)
3. **Publicar** las que estÃ©n listas
4. **Probar** en el frontend pÃºblico

Ver [PLAN_ESTRATEGICO.md](../../PLAN_ESTRATEGICO.md) para el roadmap completo.

---

## ðŸ“š DocumentaciÃ³n Relacionada

- [SCRAPING-GUIDE.md](../../docs/SCRAPING-GUIDE.md) - GuÃ­a detallada de scraping
- [REFERENCE.md](../../docs/REFERENCE.md) - Formato de datos y API
- [TAREAS_PENDIENTES.md](../../TAREAS_PENDIENTES.md) - PrÃ³ximos pasos

---

**Â¡Happy Scraping! ðŸŽ¸**
